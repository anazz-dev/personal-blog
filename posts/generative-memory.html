<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ahmad M. Nazzal — Memory as a Generative, Autoregressive Process</title>
    <link rel="stylesheet" href="../styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,300;0,400;0,700;1,300;1,400&family=PT+Serif:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
    <link rel="icon" href="../favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="container">
        <header>
            <h1><a href="../index.html">Ahmad M. Nazzal</a></h1>
            <div class="theme-toggle">
                <label for="theme-switch" class="theme-switch">
                    <input type="checkbox" id="theme-switch">
                    <span class="slider round"></span>
                </label>
            </div>
        </header>

        <div class="contents">
            <h2>Contents</h2>
            <ul>
                <li><a href="#Memory as a Generative, Autoregressive Process">Memory as a Generative, Autoregressive Process</a></li>
                <li><a href="#From Unconscious Inference to Reconstructive Memory">From Unconscious Inference to Reconstructive Memory</a></li>
                <li><a href="#The Brain as a Prediction Machine: Predictive Coding and the Bayesian Brain">The Brain as a Prediction Machine: Predictive Coding and the Bayesian Brain</a></li>
                <li><a href="#Autoregression Theory of Cognition: Memory as Generative Recall">Autoregression Theory of Cognition: Memory as Generative Recall</a></li>
                <li><a href="#New Frontiers: Implications for Therapy and Learning">New Frontiers: Implications for Therapy and Learning</a></li>
            </ul>
        </div>

        <main>
            <article class="post">
                <h1 class="post-title">Memory as a Generative, Autoregressive Process</h1>
                <p class="post-date">July 27, 2025</p>

                <div class="post-content">
                    <h2 id="Memory as a Generative, Autoregressive Process">Memory as a Generative, Autoregressive Process</h2>
                    <p>The idea that the mind actively infers or constructs reality has deep historical roots. As early as the 1860s, German scientist Hermann von Helmholtz suggested that perception is not a direct readout of the world, but a kind of unconscious reasoning. The brain “fills in” sensory information by drawing on prior knowledge – an idea he called unconscious inference[1]. For example, if one object looks smaller than another, the mind infers it’s likely farther away, automatically generating a sense of depth[1]. This was a radical departure from viewing the brain as a passive mirror; instead, even basic perception was seen as an active guess by the brain.
                    Decades later, this constructive view made its way into the study of memory. In 1932, British psychologist Sir Frederic Bartlett published Remembering, a landmark book dismantling the notion of memory as a literal replay of the past. Bartlett showed that remembering “is an imaginative reconstruction or construction” heavily dependent on our schemas – organized knowledge structures built from past experience[2]. In his famous experiments, people recalling an unfamiliar folk tale unconsciously altered details to fit their own cultural expectations. Bartlett borrowed the term schema from neurologist Henry Head, defining it as an “active organization of past experiences” that shapes how new information is understood and later recalled[2]. Rather than retrieving a perfect snapshot, the mind reconstructs events using these schemas as scaffolding. Bartlett even described memory retrieval as “turning round upon one’s own schemata,” meaning that when we need to remember something, we actively transform and recombine bits of stored knowledge to meet the present need[3][4]. This can produce errors – omissions, distortions, even outright inventions – but Bartlett argued such memory distortions are a byproduct of an adaptive system. Memory is built to flexibly assemble past information to help us in the present, not to serve as an exact record. Thus, from early on, scientists recognized “memory is not like a tape recorder”; it is more like an imaginative reconstruction process[5].
                    Through the mid-20th century, cognitive psychology continued to amass evidence for memory’s constructive nature. Researchers found that people will confidently remember details that were never present, if those details are consistent with an existing schema or expectation. Classic studies by Elizabeth Loftus, for instance, showed that wording of a question can make people “remember” broken glass at a car accident that in fact had none – the mind pragmatically fills in what seems plausible. Psychologist Ulric Neisser quipped that we are all occasionally victims of “a memory that never happened,” highlighting that recall is an act of reconstruction. Far from indicating a faulty system, many modern theorists (such as Daniel Schacter) argue these constructive “errors” are the flipside of a valuable feature: our memories are designed to be flexible and adaptive. We can simulate possible futures, imagine alternatives, and extract general lessons precisely because we do not store every literal detail. In fact, neuroscientists later observed that the same brain network – the hippocampus and connected cortical regions – is active when remembering past events and when imagining future or hypothetical events[6]. This overlap suggests that memory and imagination share a constructive engine, allowing us to “time-travel” in our mind. By the end of the 20th century, the field had largely embraced what Bartlett intuited: memory is an active, constructive process rather than a passive repository.</p>

                    <h2 id="The Brain as a Prediction Machine: Predictive Coding and the Bayesian Brain">The Brain as a Prediction Machine: Predictive Coding and the Bayesian Brain</h2>
                    <p>In recent decades, cognitive science and neuroscience have converged on a powerful idea: the brain is essentially a prediction machine. According to the theory of predictive coding (or the broader predictive processing framework), the brain is constantly generating and updating an internal model of the world, and using that model to anticipate the incoming flow of sensory information[9]. In simple terms, our cortex is forever guessing what it’s about to see, hear, and feel – and these guesses are compared to actual sensory inputs. The differences (prediction errors) are then fed back to update the internal model[9][7]. This cycle of prediction and error correction is thought to be a core principle of neural processing, allowing us to learn from surprises and make increasingly refined predictions about our environment.
                    While these ideas were formalized in the 1990s and 2000s (notably by researchers like Rao and Ballard in vision science[10], and Karl Friston with the Free Energy Principle), their lineage traces back to the likes of Helmholtz. In fact, Helmholtz’s unconscious inference is often cited as the “theoretical ancestor” of predictive coding[1] – the recognition that perception involves guesswork based on prior knowledge. Mid-20th century psychologists also presaged predictive coding: Jerome Bruner in the 1940s showed that our needs and expectations influence perception (the “New Look” psychology), demonstrating that what we expect to see can shape what we actually perceive[11]. This was an early proof that top-down processes (beliefs, context, memories) interact with bottom-up sensory data in constructing our perceptual reality.
                    In a modern predictive coding view, the brain maintains a hierarchical generative model of the world that tries to explain the causes of sensory inputs[7]. Higher regions of the brain send predictions downward (e.g. “I expect to see a face here”), while lower regions send error signals upward when reality deviates from expectation (“the face prediction doesn’t match the actual image; adjust the model”)[7]. Crucially, this framework is fundamentally Bayesian – it combines prior expectations (priors) with sensory evidence to arrive at the most probable interpretation of the world[12]. In other words, the brain constantly computes: Given my prior knowledge, what are the odds that this is what’s out there? If new evidence strongly contradicts the prediction, the brain updates its beliefs (learning occurs); if the evidence fits, the brain’s model is reinforced and can suppress the sensory detail (we don’t notice the refrigerator’s hum after a while, for example, because it was predicted). This way, the brain minimizes “surprise” or prediction error over time, which some theorists argue is the fundamental drive of all neural systems.
                    So what does this have to do with memory? Initially, predictive coding was developed to explain perception, but its implications are much broader. If the brain is always generating guesses, then retrieving a memory might be just another mode of prediction. In fact, from the predictive processing perspective, perceiving, remembering, and even imagining can be seen as variations of the same generative process, differing mainly in how much comes from the outside world versus the inside model. Remembering something would mean the brain’s internal model produces a pattern (of neural activity) that matches a past event, with minimal input from outside – essentially a controlled hallucination of the past. Cognitive neuroscientists have begun casting episodic memory recall in these terms: the hippocampus and cortex replay or generate activity patterns to “reconstruct” a previous event, guided by cues and prior knowledge[13][14]. Within a predictive coding scheme, one can imagine the hippocampus initiating a top-down cascade that reactivates cortical representations (like visual, auditory details of a memory) – in effect, a self-fulfilling prediction that brings a past scene to mind. Indeed, a recent hypothesis by Barron, Auksztulewicz, and Friston suggests that memory recall might actually arise from “fictive” prediction errors: the brain treats the absence of expected sensory input as an error to be corrected by hallucinating the memory[15]. In their framework, recalling an event is the brain’s generative model training itself – producing the remembered experience (in our mind’s eye) to reduce the gap between what is currently sensed and what is expected based on past learning[15].
                    Neurophysiological evidence supports tight links between memory and prediction. The hippocampus, long known as a key memory structure, also exhibits striking predictive activity. For example, neurons in the hippocampus fire sequences that anticipate future locations as an animal navigates a space – effectively coding for upcoming events in the immediate future[14]. The hippocampus is anatomically situated to broadcast signals widely to the neocortex[16], which makes it well-suited for orchestrating the reactivation of a past experience (during recall) or the simulation of a future one. Meanwhile, the prefrontal cortex – often associated with working memory, planning, and executive control – sits at the top of many cortical hierarchies and helps apply context and goals to what we perceive and remember. Modern research indicates that bidirectional interaction between hippocampus and prefrontal cortex is crucial for memory: the hippocampus provides detailed content (the who, what, where of an event) while the prefrontal regions provide context, relevance, and control over retrieval[17][18]. In predictive coding terms, the prefrontal cortex might set the high-level “prior” (“I need the memory of my prom night to answer this question”) and the hippocampus generates the content to meet that demand, through pattern completion. If either of these components falters – a hippocampus that can’t generate the details, or a prefrontal cortex that can’t provide guiding cues – memory failures ensue. We will see examples of this shortly, in the context of disorders.
                    In summary, contemporary neuroscience envisions the brain as constantly guessing and checking, and memory fits naturally into this paradigm. Remembering is less like opening a saved file and more like running a generative model that outputs a plausible reconstruction of an event. This brings us to a provocative new twist on these ideas – one that explicitly compares human memory to the workings of cutting-edge artificial intelligence.</p>

                    <h2 id="Autoregression Theory of Cognition: Memory as Generative Recall">Autoregression Theory of Cognition: Memory as Generative Recall</h2>
                    <p>A bold formulation of the “memory as generation” principle comes from cognitive scientist Elan Barenholtz, who has proposed what he calls an Autoregression Theory of Cognition. The term autoregression (familiar from statistics and machine learning) refers to a process that feeds its past outputs back into itself. For instance, modern AI text generators like GPT produce words one at a time, each new word based on the sequence of previous words – in essence, the model is continually using its own recent output as part of the input for the next step[19]. Barenholtz argues that human cognition may operate in a similar autoregressive, generative manner: the brain produces one mental “step” which becomes input for the next, continuously generating our stream of thoughts, perceptions, and memories in real-time[19][20].
                    When it comes to memory, this theory suggests that “remembering” is not about retrieving stored content at all – it’s about your brain synthesizing a believable version of the experience on the fly[21][22]. Barenholtz puts it dramatically: “There is no image of your mother [stored in the brain].” If someone asks you to remember your mother’s face, your brain essentially prompts its generative model: “Give me an image of Mom.” In that moment, the brain’s networks produce an image (or a concept, sound, etc.) that looks like your mother – and that output is what you experience as a memory[23][24]. But unless that process is running, there is no fixed picture of your mother hidden in some memory vault waiting to be accessed[23][24]. The memory exists only when generated. This is akin to how a large language model doesn’t store entire paragraphs verbatim; instead it encodes statistical regularities and generates text dynamically. By this view, your brain is more like an AI storyteller than a library – it recreates the story when needed, based on learned patterns.
                    This autoregressive account is a radical departure from the traditional “storage and retrieval” metaphor for memory. Barenholtz acknowledges that it defies our intuitive feeling of remembering. Subjectively, when you recall an event, it seems as if a stored image or recording popped into consciousness. But he argues this is an illusion created by the brain’s efficiency. Because the generative process is so fast and usually accurate, we feel like the memory was retrieved whole. In reality (according to the theory), the brain had to compose that memory. It just did so on demand and using subconscious inferences, so we don’t realize the constructive work that went into it[22][24]. Notably, this aligns with Bartlett’s observations from 90 years earlier, now reframed in terms of modern computation. Bartlett saw that memories are assembled from pieces (schemata + bits of the actual event) and are prone to logical errors or filling in gaps. Barenholtz’s framework offers a mechanistic spin on this: the brain’s generative model produces what probably happened, given the cues and its learned parameters, which is why our memories can be so vivid yet sometimes so wrong.
                    Under the Autoregression Theory, many puzzling aspects of memory make new sense. For example, why do we sometimes only recall something when prompted by a specific cue? (Answer: because the right prompt provides the initial input that kicks off the generative process in the needed direction, much like giving the first few words of a prompt to an AI model.) Why do memories become distorted or filled with confabulations? (Perhaps the generative model is over-eager to fit input cues to a familiar pattern, or has to fill gaps with its best guess – analogous to an AI “hallucinating” details when data is sparse[25][26].) Even the existence of false memories can be reinterpreted: if the brain’s model generates a plausible scene that never actually occurred, one might later mistake it for a real memory, especially if it fits one’s schema. In Barenholtz’s words, “memories, in some ways, aren’t real… they’re not the things we intuitively feel they are. But at the same time, they’re very real in the sense that we can generate them on demand”[24]. In other words, the experience of remembering is real – we do see the image of Mom’s face in our mind – but that image is a dynamic construct rather than a retrieved file.
                    This hypothesis brings the human brain into alignment with generative AI systems. It suggests that technologies like large language models are not just metaphorically similar to cognition, but might be operating on fundamentally analogous principles[27][28]. The architectures we built to emulate intelligence (autoregressive neural networks) could be mirroring how biological intelligence itself works[29]. Naturally, such claims are under active debate. Not all cognitive scientists agree that the brain lacks any stored representations – perhaps memory involves both generative and stored elements (for example, we might store fragments that are assembled generatively). It’s an ongoing area of research and theorizing. Nonetheless, the Autoregression Theory of Cognition serves as a provocative framework to explore how a generative memory system would handle successes and failures – especially when things go wrong.</p>


                    <h2 id="When the Generative Memory System Fails: Clues from Disorders">When the Generative Memory System Fails: Clues from Disorders</h2>
                    <p>If memory is an act of generation, then memory failures might be understood as failures of the generative process. This view can cast conditions like Alzheimer’s disease, autism, and ADHD in a new light – focusing on disruptions in how the brain creates and updates its internal models. Rather than simply losing “stored files” (the traditional view of memory loss), disorders may involve faulty predictions, broken feedback loops, or mis-calibrated weighting of prediction vs. input.Take Alzheimer’s disease (AD), the most common form of dementia. Early in Alzheimer’s, the hippocampus (our brain’s memory hub) is one of the first regions to suffer damage. In a generative framework, the hippocampus is crucial for constructing the rich details of an event by reactivating cortical patterns[13]. When it atrophies, the brain can no longer effectively generate those detailed internal simulations. As a result, an Alzheimer’s patient cannot vividly re-create past episodes – the generative engine lacks fuel. Studies show that individuals with mild Alzheimer’s have difficulty not only recalling past events, but also imagining new experiences in the future[30]. In one experiment, when asked to envision a simple scenario (like lying on a beach), Alzheimer’s patients produced far fewer details than healthy older adults, both for memories and imagined events[30]. It’s as if the constructive simulation capability has broken down, consistent with hippocampal damage. Additionally, without reliable top-down generative guidance, patients may become disoriented – unable to predict what should be happening next based on context. They often ask the same questions repeatedly or get lost, which could reflect an inability to form and update the predictive model of their situation (where they are, what they are doing). Interestingly, some dementia patients also experience confabulations – false memories or misremembered events. From the generative perspective, confabulation might occur when the brain tries to fill gaps in its model with the best guess it has, essentially over-generating when the true memory trace is too weak. Instead of “I don’t know,” the brain’s storytelling instinct produces a plausible story – but one that can be completely untrue. All these symptoms align with viewing Alzheimer’s not just as the loss of stored data, but as “aberrant predictive coding in hierarchical neural networks,” as one neuroscience review put it[31]. That review argues that many cognitive deficits in dementia (memory, language, decision-making) can be explained by a breakdown in the brain’s ability to integrate beliefs (priors) with sensory evidence, i.e. a failure of the predictive modeling that underpins normal cognition[32][33]. In short, Alzheimer’s disease cripples the brain’s generative model-building faculties – particularly in the hippocampal-cortical circuits – which explains why memory and other cognitive functions fragment in such patients.
                    Developmental disorders offer another window into predictive processing gone awry. Autism spectrum disorder (ASD) has been theorized in recent years as fundamentally a disorder of prediction. A number of researchers have proposed that autistic brains might weight incoming sensory data more heavily than prior expectations – essentially working with “hypo-priors”, or underpowered predictions[34]. If a typical brain leans a bit on memory and context to interpret the world, an autistic brain might lean more on raw sensation, because its priors are not as influential. The result, as one paper memorably put it, is that the world can feel “too real” for autistic individuals – every detail overwhelming because there isn’t enough predictive filtering[35]. For example, whereas a neurotypical person might use context (a prior) to automatically down-weight a background hum and focus on a voice, an autistic person may perceive all inputs with equal intensity. This theory helps explain both the heightened sensory sensitivities in autism and the difficulties in surprise or novelty. The internal model isn’t providing the usual guidance, so each event, even a repeat experience, can feel startlingly new. In terms of memory, if one lives in a world of weaker priors, one might also form memories differently – possibly with exceptional detail in some cases (some autistic people have astonishing rote memories or exact recall, consistent with storing literal details when the filtering is low). On the other hand, difficulties in high-level autobiographical memory or imagining future events could arise if the generative integration of information (linking events into a narrative) is atypical. Research is ongoing, but the predictive coding account of autism has gained traction as a unifying explanation: many symptoms stem from an imbalance between prior predictions and sensory evidence[36][37].
                    In ADHD (Attention-Deficit/Hyperactivity Disorder), the core challenges involve inattention, impulsivity, and poor sustained focus – essentially, difficulty in controlling what to attend to and for how long. One speculative explanation through the generative lens is that ADHD brains struggle with the precision tuning of predictions. In predictive coding, the brain not only generates predictions, it also assigns a confidence (precision) to prediction errors to decide which ones to pay attention to[33]. Neuromodulators like dopamine are thought to encode this precision weighting, telling the brain which incoming errors are important and which can be ignored[38][39]. Some researchers have suggested that in ADHD, this precision-weighting system may be faulty: either too low (so that many irrelevant stimuli grab attention as “errors” when they shouldn’t) or inconsistent over time[37]. This could manifest as distractibility – the brain’s predictive model isn’t suppressing the noise effectively – and as impulsivity, perhaps from overreacting to immediate prediction errors (leading to impulsive action) instead of holding a steadier long-term prediction. One recent theoretical paper argues that “ADHD involves a divergence in the brain’s predictive models and its ability to minimize prediction error, impacting sensory and attention processes.”[37]. In plain terms, the normal harmony between expectation and perception is a bit out of tune in ADHD. The prefrontal cortex, which normally helps enforce top-down predictions and focus (essentially telling the rest of the brain “stick to the plan, ignore distractions”), tends to be under-active or delayed in maturation in people with ADHD. This would make it harder to maintain the stable, goal-directed predictions that filter out distractions. Thus, the ADHD brain may live more “in the moment,” driven by whatever input comes, because the predictive model either isn’t strong enough or isn’t being properly applied to bias attention. Notably, treatments that improve ADHD symptoms often involve dopamine – stimulant medications boost dopaminergic signaling, which in predictive coding terms could enhance precision on the right predictions, thereby improving focus. This is a great example of how thinking in terms of generative models and prediction error may bridge the biological and cognitive aspects of a disorder.
                    These examples illustrate a recurring theme: many cognitive disorders can be viewed as disruptions in the brain’s generative self-modeling. Instead of isolated deficits (“memory center not working”), they may reflect deeper imbalances in how the brain predicts and constructs reality. This perspective is valuable because it unifies diverse symptoms under one framework and can point to new interventions. As one paper noted, describing dementias in terms of predictive coding “brings diverse clinical phenomena into a common framework…and makes specific predictions on cognitive physiology that support translational medicine”[33]. In other words, by understanding memory failure as model failure, we might devise better ways to fix the model.</p>

                    <h2 id="New Frontiers: Implications for Therapy and Learning">New Frontiers: Implications for Therapy and Learning</h2>
                    <p>Viewing memory as a generative, predictive process isn’t just an abstract theory – it suggests concrete new approaches for improving memory, treating memory disorders, and enhancing learning. Below are a few key implications for therapeutics and education:
                    Memory Rehabilitation: If memories are generated rather than retrieved, then rehabilitation for memory loss should focus on helping the brain rebuild and reinforce its generative models. Traditional memory training often emphasized rote memorization or repeated recall. The new view suggests we might instead use rich sensory and contextual cues to prompt the brain to recreate experiences. For example, virtual reality technology is being explored to allow Alzheimer’s patients or those with brain injuries to revisit familiar places and events in an immersive way. This provides the generative system with lifelike prompts to work with, potentially improving autobiographical memory recall[40]. In one case, VR scenarios of a patient’s childhood hometown or past career setting can stimulate reminiscence and help recover dormant memories by essentially jump-starting the internal model with detailed inputs. Likewise, narrative techniques – encouraging patients to actively tell and retell their life stories – might strengthen the generative pathways for constructing those memories (much like exercising a muscle). Even something as simple as using a distinctive smell or piece of music from the person’s past can serve as a cue that allows the brain’s predictive machinery to fill in associated recollections. In therapy for conditions like PTSD, a predictive processing model has inspired new techniques: for instance, Eye Movement Desensitization and Reprocessing (EMDR) has been reinterpreted as a method that induces prediction errors on a traumatic memory (by recalling it in a safe context) and forces the brain to update the memory with more accurate, non-threatening information[25][26]. Overall, memory-focused therapies are starting to shift toward this idea of reconstructing rather than directly “retrieving” – providing the right environmental support for the brain to generate the desired memory traces.
                    Cognitive Scaffolding and Assistive Tech: The generative memory framework highlights the importance of external scaffolds – tools or environmental supports that guide the brain’s predictions. For people with memory impairment or neurodevelopmental differences, external aids can be a game-changer. For example, a voice-guided digital assistant can walk someone through daily tasks step by step, effectively supplying the predictive cues they might struggle to generate internally. Such a system might give a prompt like “What do we do next when making coffee… right, we add the filter,” and wait for the person’s response[41]. This kind of assistive technology is essentially lending part of the generative model to the user, cueing their memory at each stage. Research prototypes have shown that providing verbal hints and interactive feedback can significantly improve task completion in individuals with memory/executive function deficits[41]. More low-tech scaffolds, like detailed checklists, visual schedules, or memory notebooks, serve a similar role: they structure the environment so that the brain has an easier time generating the right next step. Think of it as building a scaffold around a building under construction – the scaffold (external structure) helps the builders (cognitive processes) complete the structure with less effort. Intriguingly, because our brains are predictive, even normal education relies on scaffolding: we learn new material best when it’s introduced in a structured, contextual way that connects to what we already know. This is basically providing the brain with a framework so it doesn’t have to start predictions from scratch. For older adults, the Scaffolding Theory of Aging suggests that engaging in new and challenging activities helps the brain recruit alternative networks to compensate for losses[42]. In practice, that means encouraging seniors to use tools, mnemonics, and new strategies – not to bemoan that they can’t remember like they used to, but to consciously scaffold their cognition with cues and habits (for example, always placing keys in the same bowl by the door, or using imagery to link names to faces). All these supports acknowledge that memory is a process – one that can be augmented with a little external help.
                    Neurostimulation: Another exciting avenue is directly tuning the brain’s generative circuits through neuromodulation techniques like transcranial magnetic stimulation (TMS) or direct current stimulation. If memory recall is about orchestrating brain networks (hippocampus engaging cortex, etc.), then strategically stimulating those networks could enhance memory function. Recent studies have indeed found that repetitive TMS to memory-related regions can improve memory performance in both younger and older adults[43]. By rhythmically stimulating the lateral parietal cortex or prefrontal areas (which are connected to hippocampus), researchers were able to bias the brain into a state more conducive to recall – in essence, nudging the predictive model to activate. In clinical trials with people suffering mild cognitive impairment (often a precursor to Alzheimer’s), personalized network-targeted stimulation (tailored to each person’s brain connectivity) led to significant improvements on memory tests compared to sham treatment[44]. This suggests we can externally boost the generative recall process, perhaps by enhancing the rhythmic coordination between hippocampus and frontal cortex that underlies memory retrieval. There is also interest in using deep brain stimulation (DBS) for severe memory disorders – for instance, stimulating the fornix (a major output pathway of the hippocampus) – with some early reports of improved recall in Alzheimer’s patients. Additionally, neurofeedback and EEG-based training could allow individuals to learn to enter brain states that are optimal for encoding or retrieving information (for example, increasing certain oscillatory patterns linked to memory replay). And beyond electrical methods, even sensory stimulation at specific frequencies has shown promise: a fascinating study found that flickering light and sound at 40 Hz (which entrains brainwaves) improved memory and reduced pathology in mouse models of Alzheimer’s, hinting that similar approaches might eventually aid human patients by enhancing the brain’s natural predictive synchronization. All told, neurostimulation approaches treat the brain as a dynamic generator – and attempt to fine-tune its dynamics when they are suboptimal or impaired.
                    Educational Design and Learning Strategies: The concept of generative memory reinforces many principles of good teaching and learning – and offers some new ones. One key insight is that learners are not empty vessels into which information is poured; rather, they are active constructors of knowledge. Educational psychologist Merlin Wittrock’s Generative Learning Theory (developed back in 1974) nicely echoes this view: it posits that learners must integrate new ideas with their existing mental schemas, actively making meaning, in order to truly learn[45][46]. In Wittrock’s words, the brain “does not just passively observe its environment… it constructs its own perceptions” of lessons and problems[46]. Teachers are encouraged to have students paraphrase information, create analogies, draw concept maps, or teach others – all techniques that force the student to generate connections and explanations, rather than rote-memorize[47][48]. This aligns perfectly with the predictive memory framework: by actively generating content (explaining in one’s own words, predicting outcomes, solving problems), students are training their brains’ generative models on the material. Simply reading or listening repeatedly (passive exposure) is far less effective because it doesn’t engage the output side of memory. Strategies like active recall (testing oneself from memory) and spaced repetition leverage this as well – every time you actively recall, you are reconstructing the knowledge, which strengthens that generative capability (and highlighting gaps generates prediction errors that tell you where you need to learn more[49][50]). Curriculum design can also take predictive principles into account by building on prior knowledge: introduce new topics by relating them to familiar ones so the student’s brain has some priors to work with. This reduces cognitive load and leverages existing schemas (very much in line with Bartlett’s schema theory). Another implication is to encourage imagination and visualization in learning. If memory and imagination share processes, then having students visualize a scenario or mentally simulate a principle can encode it more deeply. For example, when teaching a science concept, a teacher might say “imagine you are a little particle moving through this electric field...” – essentially prompting the student to run a generative mental simulation, which doubles as a memorable learning experience. In summary, effective learning experiences are those that treat the student as an active predictor and generator: engaging curiosity (which generates predictions), requiring the learner to produce answers or creations, and giving feedback to update their mental models.
                    Finally, considering consciousness and creativity: if our ongoing experience is constructed by an autoregressive process, it gives a new appreciation for human creativity and the therapeutic value of self-expression. Techniques like journaling, art, or narrative therapy might help people reshape their internal generative models (for instance, reframing traumatic memories by creating a new narrative around them). The predictive brain framework even inspires some to ask whether we can consciously edit our “mental code” by choosing different predictions – an idea at the intersection of neuroscience and mindfulness/meditation practices (since meditation can be seen as learning to minimize the mind’s constant automatic predictions and stay present).
                    In conclusion, the notion of memory as a generative, autoregressive process represents a profound shift in how we understand our minds. It builds a bridge between classical psychology experiments (like Bartlett’s remembering sessions) and modern computational neuroscience (with Bayesian models and deep learning analogies). We’ve learned that what we call “memory” may be less a warehouse of facts and more a capacitor of imagination – a system that reconstructs the past and constructs the future using the same core mechanism. This view not only unifies perception, memory, and thought under one principle (the brain continually guesses and fills in), but also unifies explanations for when cognition goes wrong. As research continues, we can expect even more crossover between AI and neuroscience, each illuminating the other. And practically, by embracing our brains’ generative nature, we can develop smarter strategies to heal memory, enhance learning, and perhaps even expand the horizons of our own creativity. After all, if our memories are indeed a kind of controlled hallucination, it suggests we have more power than we realize to reshape how we see our past – and to imagine new futures.</p>

                    <h2>References</h2>
                    <p>
                    [1] [7] [8] [9] [10] [11] [12] Predictive coding - Wikipedia
                    https://en.wikipedia.org/wiki/Predictive_coding
                    [2] [3] [4] [6]  Adaptive constructive processes and the future of memory - PMC
                    https://pmc.ncbi.nlm.nih.gov/articles/PMC3815569/
                    [5] Reconstructive Memory AO1 AO2 AO3 - PSYCHOLOGY WIZARD
                    https://www.psychologywizard.net/reconstructive-memory-ao1-ao2-ao3.html
                    [13] [14] [15] [16]  Prediction and memory: A predictive coding account - PMC
                    https://pmc.ncbi.nlm.nih.gov/articles/PMC7305946/
                    [17] [18] Frontiers | Prefrontal-Hippocampal Interactions in Memory and Emotion
                    https://www.frontiersin.org/journals/systems-neuroscience/articles/10.3389/fnsys.2015.00170/full
                    [19] [20] What does the structure of large language models imply for cognition?
                    https://www.danielvanzant.com/p/what-does-the-structure-of-large
                    [21] [22] [23] [24] So-called neuroscientist: we don’t have visual memories but reconstruct them à la ChatGPT – Homo Ludditus
                    https://ludditus.com/2025/07/05/a-so-called-neuroscientist-says-we-dont-have-visual-memories-but-reconstruct-them-a-la-chatgpt/
                    [25] [26] [49] [50] Frontiers | The Predictive Processing Model of EMDR
                    https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2019.02267/full
                    [27] [28] [29] You’re Not Remembering — You’re Generating: The Autoregression Theory of Cognition | by Darwin Gosal | Jul, 2025 | Medium
                    https://medium.com/@darwingosal/youre-not-remembering-you-re-generating-the-autoregression-theory-of-cognition-84f0e3cfbdfb
                    [30] Episodic simulation of future events is impaired in mild Alzheimer's ...
                    https://www.sciencedirect.com/science/article/abs/pii/S0028393209002322
                    [31] [32] [33] Evidence and implications of abnormal predictive coding in dementia - PubMed
                    https://pubmed.ncbi.nlm.nih.gov/34240109/
                    [34] [PDF] a Bayesian explanation of autistic perception - Free
                    http://wexler.free.fr/library/files/pellicano%20(2012)%20when%20the%20world%20becomes%20too%20real.%20a%20bayesian%20explanation%20of%20autistic%20perception.pdf
                    [35] When the world becomes 'too real': a Bayesian explanation of ...
                    https://www.sciencedirect.com/science/article/abs/pii/S1364661312002008
                    [36] Predictive coding in neuropsychiatric disorders: A systematic ...
                    https://www.sciencedirect.com/science/article/pii/S014976342500020X
                    [37] (PDF) Redefining ADHD in the Light of Predictive Coding and Active ...
                    https://www.researchgate.net/publication/382169911_Redefining_ADHD_in_the_Light_of_Predictive_Coding_and_Active_Inference_A_Neurodevelopmental_Perspective
                    [38] Positive effects of methylphenidate on cognition in attention deficit ...
                    https://www.sciencedirect.com/science/article/abs/pii/S0022395622005726
                    [39] The Predictive Coding Account of Psychosis - PMC - PubMed Central
                    https://pmc.ncbi.nlm.nih.gov/articles/PMC6169400/
                    [40] Virtual Reality for the Rehabilitation of Acquired Cognitive Disorders
                    https://www.mdpi.com/2306-5354/11/1/35
                    [41] Scaffolding rehabilitation behaviour using a voice-mediated ...
                    https://pubmed.ncbi.nlm.nih.gov/20182951/
                    [42] The Adaptive Brain: Aging and Neurocognitive Scaffolding - PMC
                    https://pmc.ncbi.nlm.nih.gov/articles/PMC3359129/
                    [43] Stimulating Memory: Reviewing Interventions Using Repetitive ...
                    https://pmc.ncbi.nlm.nih.gov/articles/PMC8533697/
                    [44] Effectiveness of Personalized Hippocampal Network–Targeted ...
                    https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2818365
                    [45] [46] [47] [48] Instructional Design Models: Generative Learning Theory
                    https://elearningindustry.com/generative-learning-theory</p>


                </div>
            </article>
        </main>
    </div>

    <script src="../script.js"></script>
</body>
</html>
